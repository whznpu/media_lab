{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d5251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python run.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8b18fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#x输入是四个参数\n",
    "#[100,1,161,101]\n",
    "# 100 batch_size,一次100个音频\n",
    "# 1不清楚\n",
    "# 161不清楚\n",
    "# 101 frames帧数\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    # CNN\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.l1 = nn.Linear(101, 1024)\n",
    "        self.l2 = nn.Linear(1024, 512)\n",
    "        self.l3 = nn.Linear(512, 64)\n",
    "        self.l4 = nn.Linear(64, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x=self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        x=self.l3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "\n",
    "        '''\n",
    "        ###############################################################\n",
    "        do the forward propagation here\n",
    "        x: model input with shape:(batch_size, frame_num, feature_size)\n",
    "        frame_num is how many frame one wav have\n",
    "        feature_size is the dimension of the feature\n",
    "        ###############################################################\n",
    "        '''\n",
    "\n",
    "class FcNet(nn.Module):\n",
    "    # DNN\n",
    "    def __init__(self):\n",
    "        super(FcNet, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(784, 512)\n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 128)\n",
    "        self.l4 = torch.nn.Linear(128, 64)\n",
    "        self.l5 = torch.nn.Linear(64, 6)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)\n",
    "        '''\n",
    "        ###############################################################\n",
    "        do the forward propagation here\n",
    "        x: model input with shape:(batch_size, frame_num, feature_size)\n",
    "        frame_num is how many frame one wav have\n",
    "        feature_size is the dimension of the feature\n",
    "        ###############################################################\n",
    "        '''\n",
    "\n",
    "        \n",
    "# 建立VGG卷积神经的模型层\n",
    "def _make_layers(cfg):\n",
    "    layers = []\n",
    "    in_channels = 1\n",
    "    for x in cfg:\n",
    "        if x == 'M':  # maxpool 池化层\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:  # 卷积层\n",
    "            layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                       nn.BatchNorm2d(x),\n",
    "                       nn.ReLU(inplace=True)]\n",
    "            in_channels = x\n",
    "    layers += [nn.AvgPool2d(kernel_size=1, stride=1)]  # avgPool 池化层\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# 各个VGG模型的参数\n",
    "cfg = {\n",
    "    'VGG':[32,'M',64,'M',128,'M',128,'M'],\n",
    "    'VGG11': [32, 'M', 64, 'M', 128, 128, 'M', 256, 256, 'M', 256, 256, 'M'],\n",
    "    'VGG13': [32, 32, 'M', 64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 256, 256, 'M'],\n",
    "    'VGG16': [32, 32, 'M', 64, 64, 'M', 128, 128, 128, 'M', 256, 256, 256, 'M', 256, 256, 256, 'M'],\n",
    "    'VGG19': [32, 32, 'M', 64, 64, 'M', 128, 128, 128, 128, 'M', 256, 256, 256, 256, 'M', 256, 256, 256, 256, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "# VGG卷积神经网络\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = _make_layers(cfg[vgg_name])  # VGG的模型层\n",
    "        print(self.features)\n",
    "        self.fc1 = nn.Linear(7680, 256)            # 7680,512\n",
    "        self.fc2 = nn.Linear(256, 6)     # 输出类别5，由于全量比较大，这里只选择前5个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)  # flatting\n",
    "#         print(out.size())\n",
    "        out = self.fc1(out)  # 线性层\n",
    "        out = self.fc2(out)  # 线性层\n",
    "        return F.log_softmax(out, dim=1)  # log_softmax 激活函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "974e0165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "from __future__ import print_function\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def train(loader, model, optimizer, epoch, cuda, log_interval, verbose=True):\n",
    "    '''\n",
    "    #############################################################################\n",
    "    train the model, you can write this function partly refer to the \"test\" below\n",
    "    Args:\n",
    "        loader: torch dataloader\n",
    "        model: model to train\n",
    "        optimizer: torch optimizer\n",
    "        epoch: number of epochs to train\n",
    "        cuda: whether to use gpu\n",
    "        log_interval: how many batches to wait before logging training status\n",
    "        verbose: whether to print training log(such as epoch and loss)\n",
    "    Return:\n",
    "        the average loss of this epoch\n",
    "    #############################################################################\n",
    "    '''\n",
    "    \n",
    "\n",
    "    model.train()      # 设置为trainning模式\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        if cuda:  # 如果要调用GPU模式，就把数据转存到GPU\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)  # 把数据转换成Variable\n",
    "        optimizer.zero_grad()  # 优化器梯度初始化为零\n",
    "#         print(type(data))\n",
    "#         print(data)\n",
    "#         print(data.shape)\n",
    "        output = model(data)   # 把数据输入网络并得到输出，即进行前向传播\n",
    "#         print(output.shape)\n",
    "#         print(output)\n",
    "#         print(target.shape)\n",
    "        loss = F.nll_loss(output, target)               # 计算损失函数  \n",
    "        loss.backward()        # 反向传播梯度\n",
    "        optimizer.step()       # 结束一次前传+反传之后，更新优化器参数\n",
    "#         print(batch_idx)\n",
    "#         print(log_interval)\n",
    "#         print(epoch)\n",
    "#         print(loss.data[1])\n",
    "#         print(type(loss.data))\n",
    "        if batch_idx % log_interval == 0:          # 准备打印相关信息，args.log_interval是最开头设置的好了的参数\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(loader.dataset),\n",
    "                100. * batch_idx / len(loader), loss.item()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(loader, model, cuda, verbose=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data.item()  # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(loader.dataset)\n",
    "    if verbose:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, correct, len(loader.dataset), 100. * correct / len(loader.dataset)))\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4d9586c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.py\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from command_loader import CommandLoader\n",
    "import numpy as np\n",
    "from model import ConvNet, FcNet,VGG\n",
    "from train import train, test\n",
    "import os\n",
    "# Training settings\n",
    "def run():\n",
    "    parser = argparse.ArgumentParser(description='ConvNets for Speech Commands Recognition')\n",
    "    parser.add_argument('--train_path', default='dataset/train', help='path to the train data folder')\n",
    "    parser.add_argument('--test_path', default='dataset/test', help='path to the test data folder')\n",
    "    parser.add_argument('--valid_path', default='dataset/valid', help='path to the valid data folder')\n",
    "    parser.add_argument('--batch_size', type=int, default=100, metavar='N', help='training and valid batch size')\n",
    "    parser.add_argument('--test_batch_size', type=int, default=100, metavar='N', help='batch size for testing')\n",
    "    parser.add_argument('--arc', default='VGG', help='network architecture: ConvNet,FcNet,VGG')\n",
    "    parser.add_argument('--epochs', type=int, default=100, metavar='N', help='number of epochs to train')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR', help='learning rate')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M', help='SGD momentum, for SGD only')\n",
    "    parser.add_argument('--optimizer', default='adam', help='optimization method: sgd | adam')\n",
    "    parser.add_argument('--cuda', default=True, help='enable CUDA')\n",
    "    parser.add_argument('--seed', type=int, default=1234, metavar='S', help='random seed')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--patience', type=int, default=5, metavar='N',\n",
    "                        help='how many epochs of no loss improvement should we wait before stop training')\n",
    "    # feature extraction options\n",
    "    parser.add_argument('--window_size', default=.02, help='window size for the stft')\n",
    "    parser.add_argument('--window_stride', default=.01, help='window stride for the stft')\n",
    "    parser.add_argument('--window_type', default='hamming', help='window type for the stft')\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    args.cuda = args.cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "    # loading data\n",
    "    train_dataset = CommandLoader(args.train_path, window_size=args.window_size, window_stride=args.window_stride,\n",
    "                                window_type=args.window_type)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=args.cuda, sampler=None)\n",
    "\n",
    "    valid_dataset = CommandLoader(args.valid_path, window_size=args.window_size, window_stride=args.window_stride,\n",
    "                                window_type=args.window_type)\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=args.batch_size, shuffle=None,\n",
    "        num_workers=8, pin_memory=args.cuda, sampler=None)\n",
    "\n",
    "    test_dataset = CommandLoader(args.test_path, window_size=args.window_size, window_stride=args.window_stride,\n",
    "                                window_type=args.window_type)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=args.test_batch_size, shuffle=None,\n",
    "        num_workers=8, pin_memory=args.cuda, sampler=None)\n",
    "\n",
    "    # build model\n",
    "    if args.arc == 'ConvNet':\n",
    "        model = ConvNet()\n",
    "    elif args.arc == 'FcNet':\n",
    "        model = FcNet()\n",
    "    elif args.arc=='VGG':\n",
    "        model = VGG('VGG')\n",
    "    else:\n",
    "        model='ConvNet'\n",
    "\n",
    "    if args.cuda:\n",
    "        print('Using CUDA with {0} GPUs'.format(torch.cuda.device_count()))\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    # define optimizer\n",
    "    if args.optimizer.lower() == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    elif args.optimizer.lower() == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    best_valid_loss = np.inf\n",
    "    iteration = 0\n",
    "    epoch = 1\n",
    "\n",
    "    print(model)\n",
    "    # train with early stopping\n",
    "    while (epoch < args.epochs + 1) and (iteration < args.patience):\n",
    "        train(train_loader, model, optimizer, epoch, args.cuda, args.log_interval)\n",
    "        valid_loss = test(valid_loader, model, args.cuda)\n",
    "        if valid_loss > best_valid_loss:\n",
    "            iteration += 1\n",
    "            print('Loss was not improved, iteration {0}'.format(str(iteration)))\n",
    "        else:\n",
    "            print('Saving model...')\n",
    "            iteration = 0\n",
    "            best_valid_loss = valid_loss\n",
    "            state = {\n",
    "                'net': model.module if args.cuda else model,\n",
    "                'acc': valid_loss,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, './checkpoint/ckpt.t7')\n",
    "        epoch += 1\n",
    "\n",
    "    # test model\n",
    "    test(test_loader, model, args.cuda)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ad5c8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e24a10e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7ad41cd2f1d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tensor' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55946911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
